# jemdoc: menu{menu}{default.html}
= Kaizheng Wang

~~~
{}{img_left}{Photo/KW.jpeg}{alt text}{160}{240}

I am an assistant professor in the [https://www.ieor.columbia.edu/ Department of Industrial Engineering and Operations Research] and a member of the [https://datascience.columbia.edu/ Data Science Institute] at [https://www.columbia.edu/ Columbia University]. My research interests lie at the intersection of statistics, machine learning and optimization.\n
\n
E-mail: /kaizheng.wang/ \[@\] columbia \[DOT\] edu
\n
[https://scholar.google.com/citations?user=GWkwfBIAAAAJ&hl=en Google Scholar]
\n
[CV/CV.pdf Resume]
~~~

== Openings

I'm looking for highly motivated Ph.D. students with strong mathematical background and interest in statistics, machine learning and optimization.

== News

- Undergraduate student Sara Zhao received the prestigious Stephen D. Guarino Memorial Award, which is made annually to one member of the senior class of IEOR. Congratulations!
- I will be an Area Chair of NeurIPS 2022.
- I am organizing one session on integrative data analysis in operations research at the 2022 INFORMS Annual Meeting.
- New paper "Adaptive and robust multi-task learning" posted on [https://arxiv.org/abs/2202.05250 arXiv].
- I will be chairing a cluster on Machine Learning at the 2022 CORS-INFORMS International Conference.
- New paper "Clustering a mixture of Gaussians with unknown covariance" posted on [https://arxiv.org/abs/2110.01602 arXiv].
- I am an Area Chair of NeurIPS 2021.
- I am organizing two sessions on federated and multi-task learning at the 2021 INFORMS Annual Meeting.

== Representative Publications

- Adaptive and robust multi-task learning\n
Yaqi Duan, Kaizheng Wang ($\alpha$-$\beta$)\n
[https://arxiv.org/abs/2202.05250/ ArXiv] preprint arXiv:2202.05250, 2022.\n
\n
- Clustering a mixture of Gaussians with unknown covariance\n
Damek Davis, Mateo Díaz, Kaizheng Wang ($\alpha$-$\beta$)\n
[https://arxiv.org/abs/2110.01602/ ArXiv] preprint arXiv:2110.01602, 2021.\n
\n
- An $\ell_p$ theory of PCA and spectral clustering\n
Emmanuel Abbe, Jianqing Fan, Kaizheng Wang ($\alpha$-$\beta$)\n
*Annals of Statistics* 50(4): 2359-2385, 2022.\n
[https://arxiv.org/abs/2006.14062 ArXiv]\n
\n
- Efficient clustering for stretched mixtures: landscape and optimality\n
Kaizheng Wang, Yuling Yan, Mateo Díaz\n
*Advances in Neural Information Processing Systems (NeurIPS)*, 2020.\n
[https://arxiv.org/abs/2003.09960 ArXiv]\n
\n
- Entrywise eigenvector analysis of random matrices with low expected rank\n
Emmanuel Abbe, Jianqing Fan, Kaizheng Wang, Yiqiao Zhong ($\alpha$-$\beta$)\n
*Annals of Statistics* 48(3): 1452-1474, 2020.\n
[https://arxiv.org/abs/1709.09565 ArXiv]\n
\n
- Implicit regularization in nonconvex statistical estimation: Gradient descent converges linearly for phase retrieval, matrix completion and blind deconvolution\n
Cong Ma, Kaizheng Wang, Yuejie Chi, Yuxin Chen\n
*Foundations of Computational Mathematics* 20 (3): 451–632, 2020.\n
[https://arxiv.org/abs/1711.10467 ArXiv]\n
\n
- Distributed estimation of principal eigenspaces\n
Jianqing Fan, Dong Wang, Kaizheng Wang, Ziwei Zhu ($\alpha$-$\beta$)\n
*Annals of Statistics* 47 (6): 3009-3031, 2019.\n
[https://arxiv.org/abs/1702.06488 ArXiv]\n
\n
- Spectral method and regularized MLE are both optimal for Top-K ranking\n
Yuxin Chen, Jianqing Fan, Cong Ma, Kaizheng Wang ($\alpha$-$\beta$)\n
*Annals of Statistics* 47 (4): 2204-2235, 2019.\n
[https://arxiv.org/abs/1707.09971 ArXiv]\n
\n
$\alpha$-$\beta$: Author names are sorted alphabetically.

== Funding

Support from the following funding source is gratefully acknowledged:

- National Science Foundation (NSF) Grant DMS-2210907. Title: "Statistical and Computational Tools for Analyzing High-Dimensional Heterogeneous Data". Duration: Aug 2022 – Jul 2025. Role: PI.


== Miscellaneous

Interesting quotes:

- All models are wrong, but some are useful. -- George E. P. Box
- Theory is the first term in the Taylor series expansion of practice. -- Thomas M. Cover 

My [https://en.wikipedia.org/wiki/Erd%C5%91s_number Erdös number] is 3.

